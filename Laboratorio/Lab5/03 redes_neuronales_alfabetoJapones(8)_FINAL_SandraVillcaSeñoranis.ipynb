{"cells":[{"cell_type":"markdown","metadata":{"id":"ilEWWUkYLSv_"},"source":["# Laboratorio 5: Aplicación de Redes Neuronales.  Nombre: Sandra Villca Señoranis\n","\n","Se implementará una red neuronal con una Capa Oculta para reconocimiento de los símbolos del alfabeto japonés Hiragana.\\\n","Las imágenes están en el rango de valores de [0,255] en un formato csv.\\\n","Contiene 10 Clases de 0 a 9.\\\n","Se tiene 60000 ejemplos para entrenamiento y 10000 ejemplos para prueba."]},{"cell_type":"markdown","metadata":{"id":"avEtKPoSLifN"},"source":["##1. Importación de Librerías"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"stUHtyXwtUTc","executionInfo":{"status":"ok","timestamp":1714960689300,"user_tz":240,"elapsed":1797,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["# used for manipulating directory paths\n","import os\n","\n","# Scientific and vector computation for python\n","import numpy as np\n","\n","# Plotting library\n","from matplotlib import pyplot\n","\n","# Optimization module in scipy\n","from scipy import optimize\n","\n","# will be used to load MATLAB mat datafile format\n","# from scipy.io import loadmat\n","\n","# library written for this exercise providing additional functions for assignment submission, and others\n","# import utils\n","\n","\n","# tells matplotlib to embed plots within the notebook\n","%matplotlib inline\n","\n","#Libreria pandas y scikitlearn para el preprocesamiento de datasets\n","import pandas as pd\n","import sklearn as skl"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24996,"status":"ok","timestamp":1714960722741,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"qCQdjXpNtha3","outputId":"d6215810-860e-4859-c7a7-f4000dcd7355"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"FB5fjttVZlYE"},"source":["##2. Contenido del dataset\n","El contenido del dataset se carga en \"dataframe\", el cual Panda utilizará como unidad de información.\\\n","El conjunto de datos consta de dos archivos:\n","\n","train_data.csv\\\n","test_data.csv\\\n","El archivo train_data.csv contiene 60.000 ejemplos y etiquetas de entrenamiento. test_data.csv contiene 10.000 ejemplos de prueba y etiquetas. Cada fila consta de 785 valores: el primer valor es la etiqueta (un número del 0 al 9) y los 784 valores restantes son los valores de los píxeles (un número del 0 al 255)."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9813,"status":"ok","timestamp":1714960773260,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"M69NV8d2feds","outputId":"ad60976e-1822-4625-9b2d-ff2452691fd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["       label  0  1  2  3  4    5    6   7   8  ...  774  775  776  777  778  \\\n","0          8  0  0  0  0  0    0    0   0   0  ...  122  255   90    0    0   \n","1          7  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","2          0  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","3          1  0  0  0  0  0    0    0   0  32  ...  255   64    0    0    0   \n","4          4  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","...      ... .. .. .. .. ..  ...  ...  ..  ..  ...  ...  ...  ...  ...  ...   \n","59995      4  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","59996      9  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","59997      0  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","59998      4  0  0  0  0  0  103  225  53   0  ...    0    0    0    0    0   \n","59999      9  0  0  0  0  0    0    0   0   0  ...    0    0    0    0    0   \n","\n","       779  780  781  782  783  \n","0        0    0    0    0    0  \n","1        0    0    0    0    0  \n","2        0    0    0    0    0  \n","3        0    0    0    0    0  \n","4        0    0    0    0    0  \n","...    ...  ...  ...  ...  ...  \n","59995    0    0    0    0    0  \n","59996    0    0    0    0    0  \n","59997    0    0    0    0    0  \n","59998    0    0    0    0    0  \n","59999    0    5    0    0    0  \n","\n","[60000 rows x 785 columns]\n","              label             0             1             2             3  \\\n","count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n","mean       4.500000      0.315700      0.754383      1.236933      2.163267   \n","std        2.872305      6.356808     10.545225     13.658704     18.474369   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n","75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n","max        9.000000    255.000000    255.000000    255.000000    255.000000   \n","\n","                  4             5             6             7            8  \\\n","count  60000.000000  60000.000000  60000.000000  60000.000000  60000.00000   \n","mean       3.640333      5.816667      8.689600     12.477250     16.83380   \n","std       24.101083     30.263832     36.837178     44.035469     50.87871   \n","min        0.000000      0.000000      0.000000      0.000000      0.00000   \n","25%        0.000000      0.000000      0.000000      0.000000      0.00000   \n","50%        0.000000      0.000000      0.000000      0.000000      0.00000   \n","75%        0.000000      0.000000      0.000000      0.000000      0.00000   \n","max      255.000000    255.000000    255.000000    255.000000    255.00000   \n","\n","       ...           774           775           776           777  \\\n","count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n","mean   ...     34.513467     25.495917     17.772467     12.065067   \n","std    ...     74.740559     65.277428     55.017623     45.355241   \n","min    ...      0.000000      0.000000      0.000000      0.000000   \n","25%    ...      0.000000      0.000000      0.000000      0.000000   \n","50%    ...      0.000000      0.000000      0.000000      0.000000   \n","75%    ...      2.000000      0.000000      0.000000      0.000000   \n","max    ...    255.000000    255.000000    255.000000    255.000000   \n","\n","              778           779           780           781           782  \\\n","count  60000.0000  60000.000000  60000.000000  60000.000000  60000.000000   \n","mean       8.4089      6.019767      4.379817      2.973267      1.619700   \n","std       37.9353     31.982104     27.193214     22.296007     15.947465   \n","min        0.0000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.0000      0.000000      0.000000      0.000000      0.000000   \n","50%        0.0000      0.000000      0.000000      0.000000      0.000000   \n","75%        0.0000      0.000000      0.000000      0.000000      0.000000   \n","max      255.0000    255.000000    255.000000    255.000000    255.000000   \n","\n","                783  \n","count  60000.000000  \n","mean       0.505217  \n","std        7.678269  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        0.000000  \n","max      255.000000  \n","\n","[8 rows x 785 columns]\n"]}],"source":["dataframe = pd.read_csv('/content/gdrive/MyDrive/SIS 420/Laboratorio5/Japanese_Characters/train_data.csv')\n","print(dataframe)\n","print(dataframe.describe())"]},{"cell_type":"markdown","metadata":{"id":"WFP_NcJggFyV"},"source":["##3.Preprocesamiento del dataset train_data.cvs"]},{"cell_type":"markdown","metadata":{"id":"WiTxxSf6gLYP"},"source":["###3.1. Preprocesamiento del dataset: Separar atributos(X) de la etiqueta (y) que se va a usar para el entrenamiento\n","Los atributos(X) se van a cargar en la variable \"dataset\" y la etiqueta \"y\" en la variable \"label\"."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"B0zoC2VlgWRp","executionInfo":{"status":"ok","timestamp":1714960883132,"user_tz":240,"elapsed":337,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["dataset = dataframe.drop(\"label\", axis=1)\n","label = dataframe[\"label\"].copy()"]},{"cell_type":"markdown","metadata":{"id":"sA6he0Hygo9R"},"source":["###3.2. Preprocesamiento del dataset: Atributos con texto\n","En nuestro dataset no tenemos atributos NO NUMÉRICOS."]},{"cell_type":"markdown","metadata":{"id":"XDR0bCGQg2e2"},"source":["###Limpieza de valores NaN en los atributos."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2866,"status":"ok","timestamp":1714960888252,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"QieLb_wxha-N","outputId":"d9a9f589-aa9e-4fb7-9035-58a310d20176"},"outputs":[{"output_type":"stream","name":"stdout","text":["              label             0             1             2             3  \\\n","count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n","mean       4.500000      0.315700      0.754383      1.236933      2.163267   \n","std        2.872305      6.356808     10.545225     13.658704     18.474369   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n","75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n","max        9.000000    255.000000    255.000000    255.000000    255.000000   \n","\n","                  4             5             6             7            8  \\\n","count  60000.000000  60000.000000  60000.000000  60000.000000  60000.00000   \n","mean       3.640333      5.816667      8.689600     12.477250     16.83380   \n","std       24.101083     30.263832     36.837178     44.035469     50.87871   \n","min        0.000000      0.000000      0.000000      0.000000      0.00000   \n","25%        0.000000      0.000000      0.000000      0.000000      0.00000   \n","50%        0.000000      0.000000      0.000000      0.000000      0.00000   \n","75%        0.000000      0.000000      0.000000      0.000000      0.00000   \n","max      255.000000    255.000000    255.000000    255.000000    255.00000   \n","\n","       ...           774           775           776           777  \\\n","count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n","mean   ...     34.513467     25.495917     17.772467     12.065067   \n","std    ...     74.740559     65.277428     55.017623     45.355241   \n","min    ...      0.000000      0.000000      0.000000      0.000000   \n","25%    ...      0.000000      0.000000      0.000000      0.000000   \n","50%    ...      0.000000      0.000000      0.000000      0.000000   \n","75%    ...      2.000000      0.000000      0.000000      0.000000   \n","max    ...    255.000000    255.000000    255.000000    255.000000   \n","\n","              778           779           780           781           782  \\\n","count  60000.0000  60000.000000  60000.000000  60000.000000  60000.000000   \n","mean       8.4089      6.019767      4.379817      2.973267      1.619700   \n","std       37.9353     31.982104     27.193214     22.296007     15.947465   \n","min        0.0000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.0000      0.000000      0.000000      0.000000      0.000000   \n","50%        0.0000      0.000000      0.000000      0.000000      0.000000   \n","75%        0.0000      0.000000      0.000000      0.000000      0.000000   \n","max      255.0000    255.000000    255.000000    255.000000    255.000000   \n","\n","                783  \n","count  60000.000000  \n","mean       0.505217  \n","std        7.678269  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        0.000000  \n","max      255.000000  \n","\n","[8 rows x 785 columns]\n"]}],"source":["print(dataframe.describe())"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"HGZ5LrgYhQRP","executionInfo":{"status":"ok","timestamp":1714960894541,"user_tz":240,"elapsed":348,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["# Búsqueda de valores NaN\n","# Itera sobre cada columna y verifica si hay valores NaN\n","for col in dataframe.columns:\n","    # Verifica si hay valores NaN en la columna actual\n","    if dataframe[col].isnull().sum() > 0:\n","        # Imprime el nombre de la columna y la cantidad de valores NaN\n","        print(f\"Categoría '{col}' tiene {dataframe[col].isnull().sum()} valores NaN.\")"]},{"cell_type":"markdown","metadata":{"id":"qGRBwszJiB7-"},"source":["###Observación: No hay valores nan"]},{"cell_type":"markdown","metadata":{"id":"5NdTr0SKiKH4"},"source":["## 4. Aplicación de Redes Neuronales\n","###Al inicio cargamos el dataframe en data. Imprimimos los valores de 'X' e 'y' ."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":326,"status":"ok","timestamp":1714960900959,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"iPKROwkOtpkn","outputId":"f3d8c580-199a-4019-e703-610efbff9502"},"outputs":[{"output_type":"stream","name":"stdout","text":["(60000,)\n","(60000, 784)\n","(60000,)\n","       0  1  2  3  4    5    6   7   8    9  ...  774  775  776  777  778  \\\n","0      0  0  0  0  0    0    0   0   0    0  ...  122  255   90    0    0   \n","1      0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","2      0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","3      0  0  0  0  0    0    0   0  32  164  ...  255   64    0    0    0   \n","4      0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","...   .. .. .. .. ..  ...  ...  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n","59995  0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","59996  0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","59997  0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","59998  0  0  0  0  0  103  225  53   0    0  ...    0    0    0    0    0   \n","59999  0  0  0  0  0    0    0   0   0    0  ...    0    0    0    0    0   \n","\n","       779  780  781  782  783  \n","0        0    0    0    0    0  \n","1        0    0    0    0    0  \n","2        0    0    0    0    0  \n","3        0    0    0    0    0  \n","4        0    0    0    0    0  \n","...    ...  ...  ...  ...  ...  \n","59995    0    0    0    0    0  \n","59996    0    0    0    0    0  \n","59997    0    0    0    0    0  \n","59998    0    0    0    0    0  \n","59999    0    5    0    0    0  \n","\n","[60000 rows x 784 columns]\n","[8 7 0 ... 0 4 9]\n"]}],"source":["#  datos de entrenamiento almacenados en los arreglos X, y\n","# data = np.loadtxt(\"/content/gdrive/MyDrive/Colab Notebooks/machine learning/datasets/wine_preparado.csv\", delimiter=',')\n","data = dataframe.copy()\n","\n","# print(data)\n","#X, y = data[:, 1:], data[:,0]\n","\n","#Dataframe de Pandas\n","X = data.iloc[:, 1:]  # Seleccionar todas las filas y las columnas de 1 a 784.\n","y = data.iloc[:, 0]   # Seleccionar todas las filas y solo la columna 0.\n","\n","y = np.array([int(e) for e in y])\n","print(y.shape)\n","y = np.squeeze(y)\n","\n","\"\"\"\n","y[y == 1] = 0\n","y[y == 2] = 1\n","y[y == 3] = 2\n","\n","Xp= X[150:,:]\n","X = X[:150,:]\n","\n","yp = y[150:]\n","y = y[:150]\n","\"\"\"\n","\n","# print(npy)\n","# print(npy.shape)\n","# y = Y\n","# establecer el dígito cero en 0, en lugar del 10 asignado a este conjunto de datos\n","# Esto se hace debido a que el conjunto de datos se utilizó en MATLAB donde no hay índice 0\n","# m = y.size\n","print(X.shape)\n","print(y.shape)\n","\n","#print(Xp.shape)\n","#print(yp.shape)\n","\n","\n","print(X)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"WZHMGoYwk51f"},"source":["###Normalización"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Llh1-nI4lFS1","executionInfo":{"status":"ok","timestamp":1714960909926,"user_tz":240,"elapsed":360,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["def featureNormalize(X):\n","    X_norm = X.copy()\n","    mu = np.zeros(X.shape[1])\n","    sigma = np.zeros(X.shape[1])\n","\n","    mu = np.mean(X, axis=0)\n","    sigma = np.std(X, axis=0)\n","\n","    # Manejar el caso de desviación estándar igual a cero\n","    sigma[sigma == 0] = 1  # Si la desviación estándar es cero, establecerla a 1\n","\n","    X_norm = (X - mu) / sigma\n","\n","    return X_norm, mu, sigma"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"8DRXfRhnlSLu","executionInfo":{"status":"ok","timestamp":1714960914256,"user_tz":240,"elapsed":2021,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["# llama featureNormalize con los datos cargados\n","X_norm, mu, sigma = featureNormalize(X)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352,"status":"ok","timestamp":1714960916997,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"vOT1KRcClsoO","outputId":"fd65c3ae-22d1-438d-bafa-488b74f30af1"},"outputs":[{"output_type":"stream","name":"stdout","text":["              0         1         2         3         4         5         6  \\\n","0     -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","1     -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","2     -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","3     -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","4     -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","59995 -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","59996 -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","59997 -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","59998 -0.049664 -0.071539 -0.090561 -0.117097 -0.151046  3.211231  5.872117   \n","59999 -0.049664 -0.071539 -0.090561 -0.117097 -0.151046 -0.192200 -0.235894   \n","\n","              7         8         9  ...       774       775       776  \\\n","0     -0.283348 -0.330864 -0.379182  ...  1.170546  3.515855  1.312818   \n","1     -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","2     -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","3     -0.283348  0.298088  2.469435  ...  2.950050  0.589858 -0.323035   \n","4     -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","...         ...       ...       ...  ...       ...       ...       ...   \n","59995 -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","59996 -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","59997 -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","59998  0.920237 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","59999 -0.283348 -0.330864 -0.379182  ... -0.461781 -0.390581 -0.323035   \n","\n","            777       778       779       780       781       782       783  \n","0     -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","1     -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","2     -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","3     -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","4     -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","...         ...       ...       ...       ...       ...       ...       ...  \n","59995 -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","59996 -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","59997 -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","59998 -0.266015 -0.221666 -0.188225 -0.161064 -0.133355 -0.101566 -0.065799  \n","59999 -0.266015 -0.221666 -0.188225  0.022807 -0.133355 -0.101566 -0.065799  \n","\n","[60000 rows x 784 columns]\n"]}],"source":["print(X_norm)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"gJmt6MBbmF0z","executionInfo":{"status":"ok","timestamp":1714960923399,"user_tz":240,"elapsed":317,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["#Los datos normalizados los guardamos en X\n","X = X_norm"]},{"cell_type":"markdown","metadata":{"id":"pbcp6JjVN144"},"source":["##5. Configuración de parámetros\n","En la Capa Oculta se ha variado los 'Valores' desde 5 hasta 100 'Valores' en los diferentes intentos de entrenamiento.\\\n","Finalmente se establece 10 Valores para lo cual se tendra que calcular 7960 Thetas en toda la red neuronal."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1714960988742,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"YN2IfP_5vz8v","outputId":"bd33ca68-4063-4e72-c57d-ff4c2afb7f9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(39250,)\n","(510,)\n","(39760,)\n"]}],"source":["# Configurando parametros necesario\n","input_layer_size  = 784  # Entrada de 784 caracteristicas\n","\n","#hidden_layer_size = 100   # PRIMER INTENTO: 100 unidades ocultas\n","#hidden_layer_size = 50    # SEGUNDO INTENTO: 50 unidades ocultas\n","hidden_layer_size = 50     # TERCER INTENTO: 10 unidades ocultas\n","\n","num_labels = 10          # 10 etiquetas, de 0 a 9\n","\n","# carga los pesos en las variables Theta1 y Theta2\n","# weights = loadmat(os.path.join('/content/gdrive/MyDrive/Colab Notebooks/machine learning/data', 'ex4weights.mat'))\n","# weights = np.array()\n","pesos = {}\n","pesos['Theta1'] = np.random.rand(50, 785)\n","pesos['Theta2'] = np.random.rand(10, 51)\n","# print(pesos['Theta1'][:].shape)\n","# print(pesos['Theta2'][:].shape)\n","\n","# print(weights['Theta1'][:].shape)\n","# print(weights['Theta2'][:].shape)\n","\n","# print(weights['Theta1'][0])\n","# print(np.roll(weights['Theta1'][0], 1, axis=0))\n","# Theta1 tiene un tamaño de 25x401\n","# Theta2 tiene un tamañó de 10x26\n","# Theta1, Theta2 = weights['Theta1'], weights['Theta2']\n","Theta1, Theta2 = pesos['Theta1'], pesos['Theta2']\n","# se intercambia la ultima columa con la primera de Theta2, por cuestiones de indices que utiliza MATLAB\n","# print(Theta2)\n","# print(np.roll(Theta2, 1, axis=0))\n","\n","# Theta2 = np.roll(Theta2, 1, axis=0)\n","\n","# Desenrollar parámetros\n","print(Theta1.ravel().shape)\n","print(Theta2.ravel().shape)\n","\n","nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n","print(nn_params.shape)"]},{"cell_type":"markdown","metadata":{"id":"pRGgGSRbPiQz"},"source":["##6. Aplicación de la Sigmoide\n","Nos permite transformar una regresión que nos da un valor lineal, mediante la función de activación de la Sigmoide, en una distribución de Probabilidad entre 0 y 1."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"IYkAveQh0e87","executionInfo":{"status":"ok","timestamp":1714961030564,"user_tz":240,"elapsed":3,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["def sigmoid(z):\n","    \"\"\"\n","    Computes the sigmoid of z.\n","    \"\"\"\n","    return 1.0 / (1.0 + np.exp(-z))\n","\n","\n","def sigmoidGradient(z):\n","\n","    g = np.zeros(z.shape)\n","\n","    g = sigmoid(z) * (1 - sigmoid(z))\n","\n","    return g"]},{"cell_type":"markdown","metadata":{"id":"w9ORjICcQOcM"},"source":["##7. Función de Costo\n","En la Propagación hacia atrás: Se ajustan los valores de Theta para lo cual también se calculan las diferncias delta. Ejemplo delta_3 que es la diferencia entre el valor predicho y el grand true (y_matrix).\\\n","En la ecuación de Costo se ha agregado un valor pequeño (epsilon) al logaritmo para evitar el logaritmo de cero np.log(a3 + epsilon) -> np.log(a3 + 0.00000001).\\\n","Se aplica también el criterio de regularización."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Aevzq-rt0vKn","executionInfo":{"status":"ok","timestamp":1714961036950,"user_tz":240,"elapsed":335,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["def nnCostFunction(nn_params,\n","                   input_layer_size,\n","                   hidden_layer_size,\n","                   num_labels,\n","                   X, y, lambda_= 0.0):\n","\n","    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n","    # for our 2 layer neural network\n","    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n","                        (hidden_layer_size, (input_layer_size + 1)))\n","\n","    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n","                        (num_labels, (hidden_layer_size + 1)))\n","\n","    m = y.size\n","\n","    J = 0\n","    Theta1_grad = np.zeros(Theta1.shape)\n","    Theta2_grad = np.zeros(Theta2.shape)\n","\n","    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    a2 = sigmoid(a1.dot(Theta1.T))\n","    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n","\n","    a3 = sigmoid(a2.dot(Theta2.T))\n","\n","    # print(\"-\"*20)\n","    # print(y.shape)\n","    # print(y.reshape(-1))\n","    # print(\"-\"*20)\n","    y_matrix = y.reshape(-1)\n","    # print(y.shape)\n","    y_matrix = np.eye(num_labels)[y_matrix]\n","    # print(y_matrix)\n","\n","    temp1 = Theta1\n","    temp2 = Theta2\n","\n","    # Agregar el termino de regularización\n","\n","    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n","\n","    J = (-1 / m) * np.sum((np.log(a3 + 0.00000001) * y_matrix) + np.log(1 - a3 + 0.00000001) * (1 - y_matrix)) + reg_term\n","\n","    # Backpropogation\n","\n","    delta_3 = a3 - y_matrix\n","    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n","\n","    Delta1 = delta_2.T.dot(a1)\n","    Delta2 = delta_3.T.dot(a2)\n","\n","    # Agregar regularización al gradiente\n","\n","    Theta1_grad = (1 / m) * Delta1\n","    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n","\n","    Theta2_grad = (1 / m) * Delta2\n","    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n","\n","    # ===================== Alterntate solutions =====================\n","    # my_final_matrix = np.zeros(a3.shape)\n","    # for c in np.arange(num_labels):\n","    #    my_final_matrix[:, c] = (np.log(a3[:, c]) * (y == c)) + (np.log(1 - a3[:, c]) * (1 - (y == c)))\n","    #J = (-1 / m) * np.sum(my_final_matrix)\n","    # ================================================================\n","\n","    # ================================================================\n","    # Unroll gradients\n","    # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n","\n","    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n","\n","    return J, grad"]},{"cell_type":"markdown","metadata":{"id":"hYDlFHkNSMXZ"},"source":["##Llamada a la función de costo:\n","Se llama a la función de costo para imprimir el error calculado para los parámetros configurados.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1597,"status":"ok","timestamp":1714961048241,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"k4TjzE2h3BqL","outputId":"4b820009-eff7-42d7-cb2c-98bb3b7cb80e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Costo en parametros: 82.595030 \n"]}],"source":["lambda_ = 0\n","J, _ = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n","print('Costo en parametros: %.6f ' % J)\n"]},{"cell_type":"markdown","source":["###Evaluación de la Sigmoide para valores de z definidos.\n","Con ésto se verifica que está funcionando bien."],"metadata":{"id":"jLnDi9mbg-EV"}},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1714961057886,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"cT80ttRF-Rdv","outputId":"e15511fc-bb9d-47cd-92cb-14fa9b0134f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gradiente sigmoide evaluada con [-1 -0.5 0 0.5 1]:\n","  \n","[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n"]}],"source":["z = np.array([-1, -0.5, 0, 0.5, 1])\n","g = sigmoidGradient(z)\n","print('Gradiente sigmoide evaluada con [-1 -0.5 0 0.5 1]:\\n  ')\n","print(g)"]},{"cell_type":"markdown","source":["###8. Inicialización de los pesos\n","Los Theta se están inicializando en la variable W.\\\n","1. En W, se pasa el tamaño de salida, 1 + el tamaño de entrada.\n","2. En W, crea números random con un tamaño (L_out, 1 + L_in) para los Thetas."],"metadata":{"id":"ls9aSLx9hccp"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"EnKgJRZq-x3U","executionInfo":{"status":"ok","timestamp":1714961076344,"user_tz":240,"elapsed":327,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n","    \"\"\"\n","    Randomly initialize the weights of a layer in a neural network.\n","\n","    Parameters\n","    ----------\n","    L_in : int\n","        Number of incomming connections.\n","\n","    L_out : int\n","        Number of outgoing connections.\n","\n","    epsilon_init : float, optional\n","        Range of values which the weight can take from a uniform\n","        distribution.\n","\n","    Returns\n","    -------\n","    W : array_like\n","        The weight initialiatized to random values.  Note that W should\n","        be set to a matrix of size(L_out, 1 + L_in) as\n","        the first column of W handles the \"bias\" terms.\"\"\"\n","\n","\n","    W = np.zeros((L_out, 1 + L_in))\n","    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n","\n","    return W"]},{"cell_type":"markdown","source":["###9. Inicialización de parámetros de redes neuronales\n","Se llama a randInitializeWeights()\\\n","Se aplana y concatena initial_Theta1 e initial_Theta2"],"metadata":{"id":"7V5K7J-3ixdz"}},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1714961081683,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"znk_8rO0-6fE","outputId":"00f30038-a786-4ce5-ac40-6a6c97b029ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inicialización de parámetros de redes neuronales...\n"]}],"source":["print('Inicialización de parámetros de redes neuronales...')\n","\n","initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n","initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n","\n","# Desenrrollar parametros\n","initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"]},{"cell_type":"markdown","source":["###10. Entrenamiento de la red neuronal\n","Descripción breve:\\\n","options {} es un diccionario, no un hiperparámetro.\\\n","optimize.minimize va a maximizar o minimizar la función de costo.\\\n","En 'res' que almacena los valores de Theta se ha cambiado method a 'L-BFGS-B' (Limited-memory Broyden-Fletcher-Goldfarb-Shanno con restricciones de caja). Con este método se logra una convergencia y se obtiene los valores de Theta. Con el método 'TNC' no llega a converger.\n"],"metadata":{"id":"Ax91--FtjcsE"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"-ysYL_hX_D0k","executionInfo":{"status":"ok","timestamp":1714962648127,"user_tz":240,"elapsed":1549838,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["#  After you have completed the assignment, change the maxiter to a larger\n","#  value to see how more training helps.\n","options= {'maxiter': 1000}\n","\n","\n","#  You should also try different values of lambda\n","lambda_ = 1\n","\n","# Create \"short hand\" for the cost function to be minimized\n","costFunction = lambda p: nnCostFunction(p, input_layer_size,\n","                                        hidden_layer_size,\n","                                        num_labels, X, y, lambda_)\n","\n","# Now, costFunction is a function that takes in only one argument\n","# (the neural network parameters)\n","res = optimize.minimize(costFunction,\n","                        initial_nn_params,\n","                        jac=True,\n","                        method='L-BFGS-B',\n","                        options=options)\n","\n","# get the solution of the optimization\n","nn_params = res.x\n","\n","# Obtain Theta1 and Theta2 back from nn_params\n","Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n","                    (hidden_layer_size, (input_layer_size + 1)))\n","\n","Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n","                    (num_labels, (hidden_layer_size + 1)))"]},{"cell_type":"markdown","source":["###11. Precisión con los datos de entrenamiento"],"metadata":{"id":"asTxor0fmSbz"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"XDnQrQM4_0Ct","executionInfo":{"status":"ok","timestamp":1714963174456,"user_tz":240,"elapsed":367,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["def predict(Theta1, Theta2, X):\n","    \"\"\"\n","    Predict the label of an input given a trained neural network\n","    Outputs the predicted label of X given the trained weights of a neural\n","    network(Theta1, Theta2)\n","    \"\"\"\n","    # Useful values\n","    m = X.shape[0]\n","    num_labels = Theta2.shape[0]\n","\n","    # You need to return the following variables correctly\n","    p = np.zeros(m)\n","    h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n","    h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n","    p = np.argmax(h2, axis=1)\n","    return p"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":869,"status":"ok","timestamp":1714963181168,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"rxMinI1Y_6AG","outputId":"bf444c86-8ad8-4dc7-9671-c707028cd719"},"outputs":[{"output_type":"stream","name":"stdout","text":["[8 7 0 ... 0 4 9]\n","Training Set Accuracy: 99.941667\n"]}],"source":["pred = predict(Theta1, Theta2, X)\n","print(pred)\n","print('Training Set Accuracy: %f' % (np.mean(pred == y) * 100))"]},{"cell_type":"markdown","metadata":{"id":"6d6yxH9u-pGB"},"source":["##12. Preprocesamiento del dataset test_data.cvs para hacer Predicciones con los datos de prueba"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3724,"status":"ok","timestamp":1714963193248,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"wUxJGHhx_Up4","outputId":"dfbceb2b-e1f6-4e50-d83c-56b11db2df28"},"outputs":[{"output_type":"stream","name":"stdout","text":["      label  0   1   2  3  4   5    6    7    8  ...  774  775  776  777  778  \\\n","0         2  0  97  35  0  0   0    0    0    0  ...    0    0    0    0    0   \n","1         9  0   0   0  0  0  24   72    0    0  ...  251  149    1    0    0   \n","2         3  0   0   0  0  0   0    0    0    0  ...    0    0    0    0    0   \n","3         8  0   0   0  0  0  17  138  195  253  ...    0    0    0    0    0   \n","4         3  0   0   0  0  0   0    0    0    0  ...    0    0    0    0    0   \n","...     ... ..  ..  .. .. ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n","9995      4  0   0   0  0  0   0    0    0    0  ...    0    0    0    0    0   \n","9996      0  0   0   0  0  0   0    0    0    0  ...    0    0    0    0    0   \n","9997      9  0   0   0  0  0   0    0    0  155  ...   84   59    0    0    0   \n","9998      4  0   0   0  0  0   0    0    0    0  ...    0    0    0    0    0   \n","9999      2  0   0   0  0  0   0    0    0    0  ...    0    0    0    0    0   \n","\n","      779  780  781  782  783  \n","0       0    0    0    0    0  \n","1       0    0    0    0    0  \n","2       0    0    0    0    0  \n","3       0    0    0    0    0  \n","4       0    0    0    0    0  \n","...   ...  ...  ...  ...  ...  \n","9995    0    0    0    0    0  \n","9996    0    0    0    0    0  \n","9997    0    0    0    0    0  \n","9998    0    0    0    0    0  \n","9999    0    0    0    0    0  \n","\n","[10000 rows x 785 columns]\n","              label             0             1             2             3  \\\n","count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n","mean       4.500000      0.214500      0.664500      1.327100      2.275500   \n","std        2.872425      4.781064      9.768116     14.244901     19.004845   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n","75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n","max        9.000000    250.000000    255.000000    255.000000    255.000000   \n","\n","                  4             5             6             7             8  \\\n","count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n","mean       4.011300      6.226400      9.277900     12.994300     17.619100   \n","std       25.193437     30.850499     37.577992     43.963013     51.081542   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","max      255.000000    255.000000    255.000000    255.000000    255.000000   \n","\n","       ...           774           775           776           777  \\\n","count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n","mean   ...     38.848400     28.138300     19.602400     14.240100   \n","std    ...     76.946009     67.034558     56.736824     48.884372   \n","min    ...      0.000000      0.000000      0.000000      0.000000   \n","25%    ...      0.000000      0.000000      0.000000      0.000000   \n","50%    ...      0.000000      0.000000      0.000000      0.000000   \n","75%    ...     19.000000      0.000000      0.000000      0.000000   \n","max    ...    255.000000    255.000000    255.000000    255.000000   \n","\n","                778           779           780           781           782  \\\n","count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n","mean      10.691900      7.980400      5.923700      3.810500      1.557900   \n","std       42.331683     36.080895     31.579744     25.048983     14.783102   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","max      255.000000    255.000000    255.000000    255.000000    255.000000   \n","\n","                783  \n","count  10000.000000  \n","mean       0.510400  \n","std        7.284559  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        0.000000  \n","max      194.000000  \n","\n","[8 rows x 785 columns]\n"]}],"source":["dataframe = pd.read_csv('/content/gdrive/MyDrive/SIS 420/Laboratorio5/Japanese_Characters/test_data.csv')\n","print(dataframe)\n","print(dataframe.describe())"]},{"cell_type":"markdown","metadata":{"id":"TsdhE72n_wc3"},"source":["###Separar atributos(X) de la etiqueta (y) que se va a usar para la predicción"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"t817AESR_3Gw","executionInfo":{"status":"ok","timestamp":1714963202706,"user_tz":240,"elapsed":336,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}}},"outputs":[],"source":["dataset = dataframe.drop(\"label\", axis=1)\n","label = dataframe[\"label\"].copy()"]},{"cell_type":"markdown","metadata":{"id":"hJKHyrH8Af-6"},"source":["##Cargamos el dataframe en data."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1714963205241,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"eVZ3jDCTAtOI","outputId":"ecfd9640-d4ce-4979-a18a-070a8477ff56"},"outputs":[{"output_type":"stream","name":"stdout","text":["(10000,)\n","(10000, 784)\n","(10000,)\n"]}],"source":["data = dataframe.copy()\n","#Dataframe de Pandas\n","Xp = data.iloc[:, 1:]  # Seleccionar todas las filas y las columnas de 1 a 784.\n","yp = data.iloc[:, 0]   # Seleccionar todas las filas y solo la columna 0.\n","\n","yp = np.array([int(e) for e in yp])\n","print(yp.shape)\n","yp = np.squeeze(yp)\n","\n","\"\"\"\n","y[y == 1] = 0\n","y[y == 2] = 1\n","y[y == 3] = 2\n","\"\"\"\n","print(Xp.shape)\n","print(yp.shape)\n","\n","#print(X)\n","#print(y)"]},{"cell_type":"markdown","source":["###13. Predicción y Precisión"],"metadata":{"id":"bm25ginvm1QD"}},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":432,"status":"ok","timestamp":1714963215900,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"1Qrmea3i_hip","outputId":"f917333f-d6c1-4c07-f4d3-128b4480e53d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 9 3 ... 0 7 7]\n","Training Set Accuracy: 58.840000\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-fcf1f7fde265>:5: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n"]}],"source":["pred = predict(Theta1, Theta2, Xp)\n","print(pred)\n","print('Training Set Accuracy: %f' % (np.mean(pred == yp) * 100))\n"]},{"cell_type":"markdown","source":["###14. Observaciones\n","Se ha realizado 8 entrenamientos con diferentes configuraciones de los parámetros.\\\n","Se observa que cuando se aumenta el tamaño de la Capa Oculta la convergencia se hace más lenta dado que se tiene que determinar miles de parámetros Theta.\\\n","Los resultados de algunos de los entrenamientos son:\\\n","PRIMER ENTRENAMIENTO:\\\n","Tamaño de la Capa Oculta: 10\\\n","Method = 'TNC'\\\n","No hay convergencia\\\n","SEGUNDO ENTRENAMIENTO:\\\n","Tamaño de la Capa Oculta: 10, maxiter = 100\\\n","Method = 'L-BFGS-B'\\\n","Costo en parámetros J: 28.58\\\n","Precisión de entrenamiento: 85.76%\\\n","Precisión de prueba: 51.98%\\\n","CUARTO ENTRENAMIENTO:\\\n","Tamaño de la Capa Oculta: 10, maxiter = 1000\\\n","Method = 'L-BFGS-B'\\\n","Costo en parámetros J: 26.99\\\n","Precisión de entrenamiento: 87.50%\\\n","Precisión de prueba: 54.50%\\\n","OCTAVO ENTRENAMIENTO:\\\n","Tamaño de la Capa Oculta: 50, maxiter = 1000\\\n","Method = 'L-BFGS-B'\\\n","Costo en parámetros J: 82.59\\\n","Precisión de entrenamiento: 99.94%\\\n","Precisión de prueba: 58.84%\\\n","\n"],"metadata":{"id":"SLPi9eHynQRi"}},{"cell_type":"markdown","source":["###15. Conclusión\n","En el octavo entrenamiento se obtiene el mejor valor de precisión (58.84) para el conjunto de prueba. No es una precisión óptima pero en éste caso se acepta.\\\n","Se podría subir la precisión del conjunto de prueba aumentando el tamaño de la Capa Oculta, sin embargo está la limitación de la capacidad de procesamiento de nuestra PC dado que lleva mucho tiempo en converger y algunas veces hay desbordamiento de la memoria.\\\n","En el procesamiento con Pytorch se puede observar que si es posible obtener una precisión alta en los conjuntos de prueba.\n"],"metadata":{"id":"tybNmQ382Oeu"}}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}